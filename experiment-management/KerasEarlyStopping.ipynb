{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div class=\"alert alert-block alert-info\" style=\"border-width:4px\">Keras Early Stopping </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook walks through how to run Keras Early stopping.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbrain.learning.experiment import *\n",
    "from sbrain.dataset.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "user_name = \"albin\"\n",
    "\n",
    "def uniquify(name):\n",
    "    import time\n",
    "    should_uniquify = True\n",
    "    if should_uniquify:\n",
    "        return name + user_name + str(time.time()).replace(\".\",\"\")\n",
    "    else:\n",
    "        return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Function\n",
    "\n",
    "For this example we use an input function where we download the Mnist data from the internet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_function(mode, batch_size, params):\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    import tensorflow as tf\n",
    "\n",
    "    local_dir = \"/workspace/shared-dir/sample-notebooks/demo-data/learning/mnist/\"\n",
    "\n",
    "    if mode == \"train\":\n",
    "        mnist = input_data.read_data_sets(local_dir, one_hot=True)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(({\"data\" : mnist.train.images}, mnist.train.labels))\n",
    "        dataset = dataset.shuffle(1000).batch(batch_size).repeat()\n",
    "        return dataset\n",
    "    else:\n",
    "        mnist = input_data.read_data_sets(local_dir, one_hot=True)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(({\"data\" : mnist.test.images}, mnist.test.labels))\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KerasExecutionHints in model_function\n",
    "\n",
    "The main difference in the API is that, we expose a new class called KerasExecutionHints which is an SBrain class. This can be used to pass arguments for early stopping and best model for keras.\n",
    "\n",
    " ```python\n",
    "\n",
    "early_stop_settings = sbrain.learning.KerasEarlyStopSettings(\n",
    "    metric_name=\"accuracy\", \n",
    "    threshold=0.8,\n",
    "    higher_is_better=True,\n",
    "    check_every_n_seconds=5\n",
    ")\n",
    "exec_hints = sbrain.learning.KerasExecutionHints(early_stop_settings=early_stop_settings)\n",
    "\n",
    "```\n",
    "\n",
    "- **metric_name** - Name of the metric to look for early stopping, example - accuracy, loss etc. The name should match the metric added to graph\n",
    "- **threshold** - Threshold value beyond which the training should stop.\n",
    "- **higher_is_better** - Define the \"best\" notion, whether higher is better or lower is better. True for accuracy, False for loss.\n",
    "- **check_every_n_seconds** - How often should the training code check whether the threshold has been crossed.\n",
    "\n",
    "\n",
    "Model function in keras can return this additional hints parameter, in case you need to use the early stopping feature. Keras model function can work without this additional parameter also. SBrain checks whether the return type is a tuple and if so, interprets the first elements as a keras model and the second as execution hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model_function(params):\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Activation, InputLayer, Input\n",
    "    from keras.optimizers import SGD\n",
    "    layers = []\n",
    "    layers.append(Dense(64, activation='relu', input_shape=[784], name=\"data\"))\n",
    "    layers.append(Dropout(0.5))\n",
    "    layers.append(Dense(64, activation='relu'))\n",
    "    layers.append(Dropout(0.5))\n",
    "    layers.append(Dense(10, activation='softmax'))\n",
    "\n",
    "    model = Sequential(layers=layers)\n",
    "\n",
    "    decay = params[\"decay\"]\n",
    "    momentum = params[\"momentum\"]\n",
    "    sgd = SGD(lr=0.01, decay=decay, momentum=momentum, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    keras_early_stop_settings = KerasEarlyStopSettings(metric_name=\"accuracy\", threshold=0.5, higher_is_better=True, check_every_n_seconds=4)\n",
    "    keras_exec_hints = KerasExecutionHints(early_stop_settings=keras_early_stop_settings)\n",
    "    return model, keras_exec_hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rest of it\n",
    "\n",
    "No change for the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator.NewClassificationEstimator(keras_model_fn=keras_model_function)\n",
    "name = uniquify(\"MyMnistKerasEstimator\")\n",
    "estimator = Estimator.create(name, \"KerasEstimator\", estimator)\n",
    "\n",
    "hyper_parameters = HParams(iterations=20000, batch_size=128, decay=1e-6, momentum=0.9)\n",
    "rc = RunConfig(no_of_ps=1, no_of_workers=2, summary_save_frequency=30, \n",
    "               run_eval=True, use_gpu=False, checkpoint_frequency_in_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = uniquify(\"MyMnistKerasExperiment\")\n",
    "experiment = Experiment.run(experiment_name=name,\n",
    "                     description=\"Mnist Keras Experiment\",\n",
    "                     estimator=estimator,\n",
    "                     hyper_parameters=hyper_parameters,\n",
    "                     run_config=rc,\n",
    "                     dataset_version_split=None,\n",
    "                     input_function=input_function)\n",
    "\n",
    "job = experiment.get_single_job()\n",
    "print(\"tensorboard url\")\n",
    "print(job.get_tensorboard_url())\n",
    "\n",
    "print(job.has_finished())\n",
    "\n",
    "job.wait_until_finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets wait until it is done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.wait_until_finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally print the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is the job success?? : {}\".format(job.is_success()))\n",
    "print(\"Model metrics..\")\n",
    "print(job.get_model().model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}