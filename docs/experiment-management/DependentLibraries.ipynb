{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div class=\"alert alert-block alert-info\" style=\"border-width:4px\">How to load dependent libraries in user functions </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through on how to load dependent libraries in a user function.\n",
    "\n",
    "Every user now has a private folder under his session, in the location /home/jovyan/src. This folder is only available for a specific user. All sessions under the user share this directory. \n",
    "\n",
    "Any python files under this directory is automatically available in the PYTHONPATH of the jupyter notebooks and cluster jobs. This will help the user organize the code better.\n",
    "\n",
    "An example is given below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the below cell to make a file called \"mylib.py\" under /home/jovyan/src. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /home/jovyan/src/mylib.py\n",
    "\n",
    "\n",
    "## A simple test function\n",
    "def my_pretty_function():\n",
    "    print(\"*\"*100)\n",
    "    print(\"pretty function\")\n",
    "    print(\"!\"*100)\n",
    "\n",
    "\n",
    "## A model builder function which will get called from user model function\n",
    "def my_special_mnist_modelfn(features, labels, mode, params):\n",
    "    import tensorflow as tf\n",
    "\n",
    "    net = tf.feature_column.input_layer(features, [tf.feature_column.numeric_column(\"data\", shape=(784))])\n",
    "    # labels = tf.one_hot(labels, 2) ## either or\n",
    "    for units in [20, 20]:\n",
    "        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n",
    "\n",
    "    # Compute logits (1 per class).\n",
    "    # logits = tf.layers.dense(net, 2, activation=None) ## either or\n",
    "    logits = tf.layers.dense(net, 10, activation=None)\n",
    "\n",
    "    # Compute predictions.\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids': predicted_classes[:, tf.newaxis],\n",
    "            'probabilities': tf.nn.softmax(logits),\n",
    "            'logits': logits,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Compute loss.\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\n",
    "\n",
    "    # Compute evaluation metrics.\n",
    "    labels_to_compare = tf.argmax(labels, 1)\n",
    "    accuracy = tf.metrics.accuracy(labels=labels_to_compare,\n",
    "                                   predictions=predicted_classes,\n",
    "                                   name='acc_op')\n",
    "    metrics = {'accuracy': accuracy}\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # Create training op.\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op,\n",
    "                                      training_chief_hooks=None\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now below we start a regular job which uses this dependent module. Note that the model function loads the function from the dependent module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbrain.learning.experiment import *\n",
    "from sbrain.dataset.dataset import *\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "def input_function(mode, batch_size, params):\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    import tensorflow as tf\n",
    "    from mylib import my_pretty_function\n",
    "\n",
    "    my_pretty_function()\n",
    "\n",
    "    local_dir = \"/workspace/shared-dir/sample-notebooks/demo-data/learning/mnist/\"\n",
    "\n",
    "    if mode == \"train\":\n",
    "        mnist = input_data.read_data_sets(local_dir, one_hot=True)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(({\"data\" : mnist.train.images}, mnist.train.labels))\n",
    "        dataset = dataset.shuffle(1000).batch(batch_size).repeat()\n",
    "        return dataset\n",
    "    else:\n",
    "        mnist = input_data.read_data_sets(local_dir, one_hot=True)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(({\"data\" : mnist.test.images}, mnist.test.labels))\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def my_model_function_with_mnist(features, labels, mode, params):\n",
    "\n",
    "    from mylib import my_pretty_function, my_special_mnist_modelfn\n",
    "\n",
    "    my_pretty_function()\n",
    "\n",
    "    return my_special_mnist_modelfn(features, labels, mode, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We submit the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator.NewClassificationEstimator(model_fn=my_model_function_with_mnist)\n",
    "name = \"BestModelEstimator\" + str(time.time()).replace(\".\", \"\")\n",
    "estimator = Estimator.create(name, \"Hello\", estimator)\n",
    "\n",
    "hyper_parameters = HParams(iterations=5000, batch_size=10)\n",
    "rc = RunConfig(no_of_ps=1, no_of_workers=1, summary_save_frequency=5000, run_eval=True, use_gpu=False, checkpoint_frequency_in_steps=500)\n",
    "\n",
    "exper = Experiment.run(experiment_name=\"BestModelEstimator\" + str(time.time()).replace(\".\", \"\"),\n",
    "                       description=\"Really first model\",\n",
    "                       estimator=estimator,\n",
    "                       hyper_parameters=hyper_parameters,\n",
    "                       run_config=rc,\n",
    "                       dataset_version_split=None,\n",
    "                       input_function=input_function)\n",
    "job = exper.get_single_job()\n",
    "print(job.__dict__)\n",
    "print(\"\")\n",
    "print(\"tensorboard url\")\n",
    "print(job.get_tensorboard_url())\n",
    "\n",
    "job.has_finished()\n",
    "\n",
    "job.wait_until_finish()\n",
    "\n",
    "print(\"Is the job success?? : {}\".format(job.is_success()))\n",
    "\n",
    "print()\n",
    "print(\"Model metrics..\")\n",
    "print(job.get_model().model_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows how to use dependent modules under /home/jovyan/src folder in the user functions.\n",
    "\n",
    "CAVEAT: Please note that this is a dynamically loaded library. Even if the estimator is saved with a previous version of dependent files, when the job is run, it will point to the latest version of dependent module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}